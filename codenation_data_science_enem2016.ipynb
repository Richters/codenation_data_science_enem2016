{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "pd.set_option('display.float_format', lambda x: '%.10f' % x)\n",
    "from random import uniform, randint\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, RandomizedSearchCV\n",
    "import xgboost as xgb\n",
    "\n",
    "# Leitura das bases de treino/validação e teste. Foram consideradas apenas as variáveis que existem na base de teste.\n",
    "df = pd.read_csv(r'train.csv',index_col=0)\n",
    "df_test = pd.read_csv(r'test.csv')\n",
    "df.reset_index(inplace=True)\n",
    "cols = list(df_test.columns)\n",
    "cols.append('NU_NOTA_MT')\n",
    "\n",
    "# Codificação das variáveis de Cor de Prova para números inteiros\n",
    "encoder = LabelEncoder()\n",
    "for c in ['CO_PROVA_CN','CO_PROVA_CH','CO_PROVA_LC','CO_PROVA_MT']:\n",
    "    df[c] = encoder.fit_transform(df[c])\n",
    "    df_test[c] = encoder.transform(df_test[c])\n",
    "\n",
    "# As observações que não possuem variáveis resposta (NU_NOTA_MT) serão desconsideradas\n",
    "df = df[~df['NU_NOTA_MT'].isnull()]\n",
    "df = df[cols]\n",
    "\n",
    "# Variáveis ignoradas\n",
    "drops = ['TP_SEXO', \n",
    "         'TP_COR_RACA',\n",
    "         'TP_ENSINO',\n",
    "         'TP_DEPENDENCIA_ADM_ESC',\n",
    "         'NU_INSCRICAO',\n",
    "         'CO_UF_RESIDENCIA',\n",
    "         'TP_PRESENCA_CN',\n",
    "         'TP_PRESENCA_CH', \n",
    "         'TP_PRESENCA_LC',\n",
    "         'IN_CEGUEIRA']\n",
    "\n",
    "# Variáveis Discretas\n",
    "discrete = ['NU_NOTA_CN', \n",
    "            'NU_NOTA_CH', \n",
    "            'NU_NOTA_LC',\n",
    "            'NU_NOTA_COMP1', \n",
    "            'NU_NOTA_COMP2', \n",
    "            'NU_NOTA_COMP3',\n",
    "            'NU_NOTA_COMP4', \n",
    "            'NU_NOTA_COMP5', \n",
    "            'NU_NOTA_REDACAO']\n",
    "\n",
    "# Variáveis categóricas\n",
    "categorical = ['SG_UF_RESIDENCIA',\n",
    "               'NU_IDADE',\n",
    "               'TP_NACIONALIDADE',\n",
    "               'TP_ST_CONCLUSAO',\n",
    "               'TP_ANO_CONCLUIU',\n",
    "               'TP_ESCOLA',\n",
    "               'CO_PROVA_CN', \n",
    "               'CO_PROVA_CH',\n",
    "               'CO_PROVA_LC', \n",
    "               'CO_PROVA_MT',\n",
    "               'TP_LINGUA',\n",
    "               'TP_STATUS_REDACAO',\n",
    "               'Q001', \n",
    "               'Q002',\n",
    "               'Q006',\n",
    "               'Q024',\n",
    "               'Q026', \n",
    "               'Q027', \n",
    "               'Q047']\n",
    "\n",
    "# Variáveis binárias\n",
    "binaries = ['IN_TREINEIRO', \n",
    "            'IN_BAIXA_VISAO',\n",
    "            'IN_CEGUEIRA', \n",
    "            'IN_SURDEZ', \n",
    "            'IN_DISLEXIA', \n",
    "            'IN_DISCALCULIA',\n",
    "            'IN_SABATISTA', \n",
    "            'IN_GESTANTE', \n",
    "            'IN_IDOSO',\n",
    "            'Q025']\n",
    "\n",
    "# Tratamento das variáveis nas bases de treino e teste\n",
    "df.drop(columns=drops,inplace=True)\n",
    "drops.remove('NU_INSCRICAO')\n",
    "df_test.drop(columns=drops,inplace=True)\n",
    "\n",
    "df['Q025'] = df['Q025'].apply(lambda x: 0 if x == 'A' else 1)\n",
    "df_test['Q025'] = df_test['Q025'].apply(lambda x: 0 if x == 'A' else 1)\n",
    "\n",
    "df['Q027'] = df['Q027'].fillna('other')\n",
    "df_test['Q027'] = df_test['Q027'].fillna('other')\n",
    "\n",
    "df[['NU_NOTA_CN','NU_NOTA_CH']] = df[['NU_NOTA_CN','NU_NOTA_CH']].fillna(0)\n",
    "df_test = df_test.fillna(0)\n",
    "\n",
    "df['NU_IDADE'] = pd.cut(df['NU_IDADE'],bins=[0,18,25,35,45,np.inf], labels=['A','B','C','D','E'])\n",
    "df_test['NU_IDADE'] = pd.cut(df_test['NU_IDADE'],bins=[0,18,25,35,45,np.inf], labels=['A','B','C','D','E'])\n",
    "\n",
    "df[categorical] = df[categorical].astype(str)  \n",
    "df_test[categorical] = df_test[categorical].astype(str)\n",
    "\n",
    "df = pd.get_dummies(df,columns=categorical)\n",
    "df_test = pd.get_dummies(df_test,columns=categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0000000000    130\n",
       "0.0100000000     23\n",
       "0.0200000000      6\n",
       "0.1200000000      4\n",
       "0.0400000000      4\n",
       "0.0300000000      3\n",
       "0.2400000000      2\n",
       "0.0500000000      2\n",
       "0.1100000000      2\n",
       "0.3000000000      1\n",
       "0.0600000000      1\n",
       "0.1400000000      1\n",
       "0.0700000000      1\n",
       "0.0900000000      1\n",
       "Name: NU_NOTA_MT, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Análise das variáveis que influência a variância da variável resposta\n",
    "x = df.drop(columns='NU_NOTA_MT')\n",
    "y = df['NU_NOTA_MT']\n",
    "\n",
    "# Dataframe com R-quadrado das variáveis\n",
    "rsquared_df = df.corr()['NU_NOTA_MT']\n",
    "rsquared_df = (rsquared_df * rsquared_df).round(2)\n",
    "rsquared_df = rsquared_df.to_frame()\n",
    "\n",
    "# Dataframe com o p-valor do teste F \n",
    "score = f_regression(x,y)\n",
    "score_df = pd.DataFrame({'pvalue':list((map(lambda x: round(x,10),score[1])))},index=x.columns)\n",
    "\n",
    "# R quadrado e p-valor de cada variável\n",
    "features = rsquared_df.merge(score_df,how='inner',left_index=True,right_index=True).sort_values(by='NU_NOTA_MT',ascending=False)\n",
    "features['NU_NOTA_MT'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R Quadrado das variáveis > 0.0\n",
      "neg_mean_squared_error: -5930.1768994586155\n",
      "neg_mean_squared_log_error: -0.055354960035597214\n",
      "r2: 0.4045550594313646\n",
      "\n",
      "R Quadrado das variáveis > 0.01\n",
      "neg_mean_squared_error: -5965.347324074989\n",
      "neg_mean_squared_log_error: -0.05534246962425515\n",
      "r2: 0.40095281885423883\n",
      "\n",
      "R Quadrado das variáveis > 0.02\n",
      "neg_mean_squared_error: -5990.304062858963\n",
      "neg_mean_squared_log_error: -0.055329964130789236\n",
      "r2: 0.3984638535132731\n",
      "\n",
      "R Quadrado das variáveis > 0.03\n",
      "neg_mean_squared_error: -6018.633722374836\n",
      "neg_mean_squared_log_error: -0.055350010688089105\n",
      "r2: 0.39563890778709776\n",
      "\n",
      "R Quadrado das variáveis > 0.04\n",
      "neg_mean_squared_error: -6058.454176201734\n",
      "neg_mean_squared_log_error: -0.055330320893195374\n",
      "r2: 0.3916075516855435\n",
      "\n",
      "R Quadrado das variáveis > 0.05\n",
      "neg_mean_squared_error: -6071.002548438785\n",
      "neg_mean_squared_log_error: -0.05520310277402919\n",
      "r2: 0.39033279166888357\n",
      "\n",
      "R Quadrado das variáveis > 0.06\n",
      "neg_mean_squared_error: -6078.663748343119\n",
      "neg_mean_squared_log_error: -0.055199437806607674\n",
      "r2: 0.38957127195902636\n",
      "\n",
      "R Quadrado das variáveis > 0.07\n",
      "neg_mean_squared_error: -6121.7034229994515\n",
      "neg_mean_squared_log_error: -0.055083443525976675\n",
      "r2: 0.3852698323542638\n",
      "\n",
      "R Quadrado das variáveis > 0.09\n",
      "neg_mean_squared_error: -6121.703422999451\n",
      "neg_mean_squared_log_error: -0.05508344352597665\n",
      "r2: 0.3852698323542639\n",
      "\n",
      "R Quadrado das variáveis > 0.11\n",
      "neg_mean_squared_error: -6145.730067952238\n",
      "neg_mean_squared_log_error: -0.05522284739166207\n",
      "r2: 0.3828750513615705\n",
      "\n",
      "R Quadrado das variáveis > 0.12\n",
      "neg_mean_squared_error: -6293.307786347816\n",
      "neg_mean_squared_log_error: -0.05456668698830312\n",
      "r2: 0.36804264296391787\n",
      "\n",
      "R Quadrado das variáveis > 0.14\n",
      "neg_mean_squared_error: -6323.947349412321\n",
      "neg_mean_squared_log_error: -0.0535149818690535\n",
      "r2: 0.3649452431961074\n",
      "\n",
      "R Quadrado das variáveis > 0.24\n",
      "neg_mean_squared_error: -6941.579121604422\n",
      "neg_mean_squared_log_error: -0.0642042798026422\n",
      "r2: 0.30288695296871027\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation de diversos modelos de Regressão Linear.\n",
    "for i in sorted(list(features['NU_NOTA_MT'].value_counts().index))[:-1]:\n",
    "    list_features = list(features[features['NU_NOTA_MT'] > i].index)\n",
    "\n",
    "    model = LinearRegression()\n",
    "\n",
    "    cv_results = cross_validate(model,x[list_features],y,scoring=['neg_mean_squared_error','neg_mean_squared_log_error','r2'])\n",
    "    print(f'R Quadrado das variáveis > {i}')\n",
    "    print(f\"neg_mean_squared_error: {cv_results['test_neg_mean_squared_error'].mean()}\")\n",
    "    print(f\"neg_mean_squared_log_error: {cv_results['test_neg_mean_squared_log_error'].mean()}\")\n",
    "    print(f\"r2: {cv_results['test_r2'].mean()}\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Melhor modelo de Regressão Linear identificado\n",
    "final_model = LinearRegression()\n",
    "\n",
    "list_features = list(features[features['NU_NOTA_MT'] > 0.0].index)\n",
    "final_model.fit(x[list_features],y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execução do Modelo na base de teste\n",
    "df_test['NU_NOTA_MT'] = final_model.predict(df_test[list_features])\n",
    "df_test['NU_NOTA_MT'] = df_test['NU_NOTA_MT'].apply(lambda x: round(x,1))\n",
    "\n",
    "#df_test[['NU_INSCRICAO','NU_NOTA_MT']].to_csv(r'answer.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 120 candidates, totalling 600 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 600 out of 600 | elapsed: 16.0min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=XGBRegressor(base_score=0.5, booster='gbtree',\n",
       "                                          colsample_bylevel=1,\n",
       "                                          colsample_bynode=1,\n",
       "                                          colsample_bytree=1, gamma=0,\n",
       "                                          importance_type='gain',\n",
       "                                          learning_rate=0.1, max_delta_step=0,\n",
       "                                          max_depth=3, min_child_weight=1,\n",
       "                                          missing=None, n_estimators=100,\n",
       "                                          n_jobs=1, nthread=None,\n",
       "                                          objective='reg:squarederror',\n",
       "                                          random_state=42, reg...\n",
       "                                                      0.4603847214648239,\n",
       "                                                      0.5962701273150146,\n",
       "                                                      0.5642899053327559,\n",
       "                                                      0.4710427296327766,\n",
       "                                                      0.4672935915527723,\n",
       "                                                      0.47481729154299235,\n",
       "                                                      0.4363783061663216,\n",
       "                                                      0.4368058149807549,\n",
       "                                                      0.45543229722811307,\n",
       "                                                      0.559769567453264,\n",
       "                                                      0.40384731169637567,\n",
       "                                                      0.5867520088710546, ...]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=42, refit=True,\n",
       "                   return_train_score=True, scoring='neg_mean_squared_error',\n",
       "                   verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross validation de XGBoost com Grid Search de parâmetros aleatórios\n",
    "xgb_model = xgb.XGBRegressor(objective=\"reg:squarederror\",random_state=42)\n",
    "\n",
    "params = {\n",
    "    \"colsample_bytree\": [uniform(0.7, 0.3) for i in range(40)],\n",
    "    \"gamma\": [uniform(0, 0.5) for i in range(40)],\n",
    "    \"learning_rate\": [uniform(0.03, 0.3) for i in range(40)], \n",
    "    \"max_depth\": list(range(2,7)),\n",
    "    \"n_estimators\": [randint(100, 150) for i in range(40)],\n",
    "    \"subsample\": [uniform(0.6, 0.4) for i in range(40)]\n",
    "}\n",
    "\n",
    "search = RandomizedSearchCV(xgb_model, param_distributions=params, scoring='neg_mean_squared_error', random_state=42, n_iter=120, cv=5, verbose=1, n_jobs=1, return_train_score=True)\n",
    "\n",
    "search.fit(x[list_features], y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execução do XGBoost com os melhores parâmetros na base de teste e geração do arquivo de respostas do desafio\n",
    "df_test['NU_NOTA_MT'] = search.best_estimator_.predict(df_test[list_features])\n",
    "df_test['NU_NOTA_MT'] = df_test['NU_NOTA_MT'].apply(lambda x: round(x,1))\n",
    "\n",
    "df_test[['NU_INSCRICAO','NU_NOTA_MT']].to_csv(r'answer.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
